{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to scientific computing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The role of computing in science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fork form: http://jrjohansson.github.io/computing.html\n",
    "Also see: http://www.scipy-lectures.org/\n",
    "\n",
    "在傳統的觀念中我們將科學分成實驗和理論科學，但隨著近幾十年來電腦運算能力的增強，計算科學也成為一個不可或缺的要素。他與理論或實驗可說是相輔相成的。\n",
    "\n",
    "> 在大多數的科學領域中，計算工具是實驗科學和理論科學很重要的一部分，近年來發表的paper不論是屬於哪部分，大多會有數值運算、電腦模擬等結果在其中。\n",
    "\n",
    "<center>\n",
    "<img src=\"http://i.imgur.com/lyrHjEl.png\" width=\"300\">\n",
    "</center>\n",
    "\n",
    "> 我們認為如果能將計算科學發展起來將能增進科學的重現性，並有助於科學的發展。\n",
    "\n",
    "在計算科學中如何分享source code 和 data還未建立相關準則。舉例來說，很少的paper會將用來模擬的source code提供給讀者(近年來開源概念這部分有進步!)。\n",
    "\n",
    "> 近年來有些期刊編輯開始注意到這塊領域，因此例如Science等相關期刊開始要求作者要提供simulation的 source code供有興趣的讀者實驗。H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements on scientific computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replication** 和 **reproducibility** 是兩個計算科學中重要的因素。\n",
    "\n",
    "也就是論文作者要能夠讓其他研究者重現他們所說的結果，可藉由 Environment, opensource, notes 等方面來讓讀者進一步了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for managing source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要確保上面兩要素並不容易，不過我們可以藉由版本控制系統來達成。\n",
    "\n",
    "* Revision Control System (RCS) software. \n",
    "    * 包含:\n",
    "        * git (分散式)- http://git-scm.com\n",
    "        * subversion (集中式) - http://subversion.apache.org. Also known as `svn`.\n",
    "\n",
    "* Online repositories for source code: 能夠建立公開或私人的空間 \n",
    "    * 推薦服務:\n",
    "        * Github - http://www.github.com\n",
    "\n",
    "> 版本控制除了source code外也可管理 manuscripts, figures, thesis files, data files, lab logs 等等. 簡言之，任何數位內容需要保存且常常更新皆可利用此機制。另外他們也對協作很有幫助。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python](http://www.python.org/) 是一個 general-purpose, object-oriented, high-level 的程式語言\n",
    "\n",
    "他有下列特徵:\n",
    "\n",
    "* **Clean and simple language:** Easy-to-read and intuitive code, easy-to-learn minimalistic syntax but still powerful. (The first language learn in foreign?)\n",
    "* **Expressive language:** Fewer lines of code, fewer bugs, easier to maintain. (Runnable pseudo code!)\n",
    "\n",
    "> 著名的”人月神話”一書作者Fred Brooks曾說：「一個程式設計師一天能產生的程式碼行數是差不多的，無論什麼程式語言」。因此一個具有表達能力的高階程式語言，就會比低階的程式語言能完成更多功能。\n",
    "\n",
    "進一步來說:\n",
    "\n",
    "* **Dynamically typed:** No need to define the type of variables, function arguments or return types.\n",
    "* **Automatic memory management:** No need to explicitly allocate and deallocate memory for variables and data arrays. No memory leak bugs. \n",
    "* **Interpreted:** No need to compile the code. The Python interpreter reads and executes the python code directly.\n",
    "\n",
    "好處:\n",
    "\n",
    "* The main advantage is ease of programming, minimizing the time required to develop, debug and maintain the code.\n",
    "* Well designed language that encourage many good programming practices:\n",
    "    * Modular and object-oriented programming, good system for packaging and re-use of code. \n",
    "    * Documentation tightly integrated with the code. (Like javadoc)\n",
    "* A large standard library, and a large collection of add-on packages.\n",
    "\n",
    "壞處:\n",
    "\n",
    "* Since Python is an interpreted and dynamically typed programming language, the execution of python code can be slow compared to compiled statically typed programming languages, such as C.\n",
    "* Somewhat decentralized, with different environment, packages and documentation spread out at different places. (Python2, Python3, many environments...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What makes python suitable for scientific computing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://i.imgur.com/RhDOnOo.png\" width=\"600\">\n",
    "\n",
    "* Python 在計算科學上有許多優勢: \n",
    "    * Large community of users, easy to find help and documentation.\n",
    "    * Numpy: http://numpy.scipy.org - Numerical Python\n",
    "    * Scipy: http://www.scipy.org -  Scientific Python\n",
    "    * Matplotlib: http://www.matplotlib.org - Graphics library\n",
    "\n",
    "* Great performance due to close integration with time-tested and highly optimized codes written in C and Fortran:\n",
    "    * blas, altas blas, lapack, arpack, Intel MKL, ...\n",
    "\n",
    "* Good support for \n",
    "    * Parallel processing with processes and threads\n",
    "    * Interprocess communication (MPI)\n",
    "    * GPU computing (OpenCL and CUDA) (TensorFlow, Caffee...)\n",
    "\n",
    "* No license costs, no unnecessary use of research budget. (In contrats to matlab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is not only a programming language, but often also refers to the **standard implementation of the interpreter (technically referred to as [CPython](http://en.wikipedia.org/wiki/CPython)) that actually runs the python code on a computer.**\n",
    "\n",
    "There are also many different environments through which the python interpreter can be used. Each environment has different advantages and is suitable for different workflows. \n",
    "\n",
    "One strength of python is that it is versatile and can be used in complementary ways, but it can be confusing for beginners **so we will start with a brief survey of python environments that are useful for scientific computing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard way to use the Python programming language is to use the Python interpreter to run python code. At the command prompt, the command ``python`` is used to invoke the Python interpreter.\n",
    "\n",
    "For example, to run a file ``my-program.py`` that contains python code from the command prompt, use::\n",
    "\n",
    "    $ python my-program.py\n",
    "\n",
    "We can also start the interpreter by simply typing ``python`` at the command line, and interactively type python code into the interpreter. \n",
    "\n",
    "<img src=\"https://i.imgur.com/3DHedQZ.png\" width=\"600\">\n",
    "\n",
    "> This is often how we want to work when developing scientific applications, or when doing small calculations. But the standard python interpreter is not very convenient for this kind of work, due to a number of limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython is an interactive shell that addresses the limitation of the standard python interpreter, and it is a work-horse for scientific use of python. It provides an interactive prompt to the python interpreter with a greatly improved user-friendliness.\n",
    "\n",
    "<img src=\"https://i.imgur.com/A4613iQ.png\" width=\"600\">\n",
    "\n",
    "Some of the many useful features of IPython includes:\n",
    "\n",
    "* Command history, which can be browsed with the up and down arrows on the keyboard.\n",
    "* Tab auto-completion.\n",
    "* Object introspection, and automatic extract of documentation strings from python objects like classes and functions.\n",
    "* Good interaction with operating system shell.\n",
    "* Support for multiple parallel back-end processes, that can run on computing clusters or cloud services like Amazon EE2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPython notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[IPython notebook](http://ipython.org/notebook.html) is an HTML-based notebook environment for Python, similar to Mathematica or Maple. **It is based on the IPython shell, but provides a cell-based environment with great interactivity**, where calculations can be organized with document in a structured way.\n",
    "\n",
    "<img src=\"https://i.imgur.com/mtfyHU3.png\" width=\"800\">\n",
    "\n",
    "Although using a web browser as graphical interface, IPython notebooks are usually run locally, from the same computer that run the browser. To start a new IPython notebook session, run the following command:\n",
    "\n",
    "    $ ipython notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spyder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spyder](http://code.google.com/p/spyderlib/) is a MATLAB-like IDE for scientific computing with python. It has the many advantages of a traditional IDE environment, for example that everything from code editing, execution and debugging is carried out in a single environment, and work on different calculations can be organized as projects in the IDE environment.\n",
    "\n",
    "<!-- <img src=\"files/images/spyder-screenshot.jpg\" width=\"800\"> -->\n",
    "<img src=\"https://i.imgur.com/sHzVv5O.png\" width=\"800\">\n",
    "\n",
    "Some advantages of Spyder:\n",
    "\n",
    "* Powerful code editor, with syntax high-lighting, dynamic code introspection and integration with the python debugger.\n",
    "* Variable explorer, IPython command prompt, integrated documentation and help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyCharm\n",
    "\n",
    "<img src=\"https://i.imgur.com/X01yDkh.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaconda, Virtualenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly manage virtual environment and even share with others your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions of Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently two versions of python: Python 2 and Python 3. Python 3 will eventually supercede Python 2, but it is **not backward-compatible with Python 2**. A lot of existing python code and packages has been written for Python 2, and it is still the most wide-spread version. For these lectures either version will be fine, but it is probably easier to stick with Python 2 for now, because it is more readily available via prebuilt packages and binary installers.\n",
    "\n",
    "To see which version of Python you have, run\n",
    "```    \n",
    "$ python --version\n",
    "Python 2.7.3\n",
    "$ python3.2 --version\n",
    "Python 3.2.3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way set-up an scientific Python environment is to use the cross-platform package manager `conda` from Continuum Analytics. First download and install miniconda http://conda.pydata.org/miniconda.html or Anaconda (see below). Next, to install the required libraries for these notebooks, simply run:\n",
    "\n",
    "    $ conda install ipython ipython-notebook spyder numpy scipy sympy matplotlib cython\n",
    "\n",
    "This should be sufficient to get a working environment on any platform supported by `conda`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Ubuntu Linux, to installing python and all the requirements run:\n",
    "\n",
    "    $ sudo apt-get install python ipython ipython-notebook\n",
    "$ sudo apt-get install python-numpy python-scipy python-matplotlib python-sympy\n",
    "    $ sudo apt-get install spyder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MacOS X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Macports*\n",
    "\n",
    "Python is included by default in Mac OS X, but for our purposes it will be useful to install a new python environment using [Macports](http://www.macports.org/), because it makes it much easier to install all the required additional packages. Using Macports, we can install what we need with:\n",
    "\n",
    "    $ sudo port install py27-ipython +pyside+notebook+parallel+scientific\n",
    "    $ sudo port install py27-scipy py27-matplotlib py27-sympy\n",
    "    $ sudo port install py27-spyder\n",
    "\n",
    "These will associate the commands `python` and `ipython` with the versions installed via macports (instead of the one that is shipped with Mac OS X), run the following commands:\n",
    "\n",
    "    $ sudo port select python python27\n",
    "    $ sudo port select ipython ipython27\n",
    "\n",
    "*Fink*\n",
    "\n",
    "Or, alternatively, you can use the [Fink](http://www.finkproject.org/) package manager. After installing Fink, use the following command to install python and the packages that we need:\n",
    "\n",
    "    $ sudo fink install python27 ipython-py27 numpy-py27 matplotlib-py27 scipy-py27 sympy-py27\n",
    "    $ sudo fink install spyder-mac-py27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windows lacks a good packaging system, so the easiest way to setup a Python environment is to install a pre-packaged distribution. Some good alternatives are:\n",
    "\n",
    " * [Anaconda](http://continuum.io/downloads.html). The Anaconda Python distribution comes with many scientific computing and data science packages and is free, including for commercial use and redistribution. It also has add-on products such as Accelerate, IOPro, and MKL Optimizations, which have free trials and are free for academic use.\n",
    " * [Python(x,y)](http://code.google.com/p/pythonxy/). Fully open source.\n",
    " * [Enthought Python Distribution](http://www.enthought.com/products/epd.php). EPD is a commercial product but is available free for academic use.\n",
    "\n",
    "\n",
    "\n",
    "#### Note\n",
    "\n",
    "EPD and Anaconda are also available for Linux and Max OS X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * [Python](http://www.python.org). The official Python web site.\n",
    " * [Python tutorials](http://docs.python.org/2/tutorial). The official Python tutorials.\n",
    " * [Think Python](http://www.greenteapress.com/thinkpython). A free book on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python and module versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are several different versions of Python and each Python package has its own release cycle and version number (for example scipy, numpy, matplotlib, etc., which we installed above and will discuss in detail in the following lectures), it is important for the reproducibility of an IPython notebook to record the versions of all these different software packages. If this is done properly it will be easy to reproduce the environment that was used to run a notebook, but if not it can be hard to know what was used to produce the results in a notebook.\n",
    "\n",
    "To encourage the practice of recording Python and module versions in notebooks, I've created a simple IPython extension that produces a table with versions numbers of selected software components. I believe that it is a good practice to include this kind of table in every notebook you create. \n",
    "\n",
    "To install this IPython extension, use `pip install version_information`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): version-information in /projects/7171577f-a330-4f46-8f6d-303bd01a7bdc/.local/lib/python2.7/site-packages\n",
      "\u001b[33mYou are using pip version 7.1.2, however version 8.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# you only need to do this once\n",
    "!pip install version_information --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to load the extension and produce the version table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "2.7.10 64bit [GCC 5.2.1 20151010]"
        },
        {
         "module": "IPython",
         "version": "4.0.2"
        },
        {
         "module": "OS",
         "version": "Linux 4.2.0 30 generic x86_64 with Ubuntu 15.10 wily"
        },
        {
         "module": "numpy",
         "version": "1.8.2"
        },
        {
         "module": "scipy",
         "version": "0.14.1"
        },
        {
         "module": "matplotlib",
         "version": "1.4.2"
        },
        {
         "module": "sympy",
         "version": "0.7.6"
        },
        {
         "module": "version_information",
         "version": "1.0.3"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>2.7.10 64bit [GCC 5.2.1 20151010]</td></tr><tr><td>IPython</td><td>4.0.2</td></tr><tr><td>OS</td><td>Linux 4.2.0 30 generic x86_64 with Ubuntu 15.10 wily</td></tr><tr><td>numpy</td><td>1.8.2</td></tr><tr><td>scipy</td><td>0.14.1</td></tr><tr><td>matplotlib</td><td>1.4.2</td></tr><tr><td>sympy</td><td>0.7.6</td></tr><tr><td>version_information</td><td>1.0.3</td></tr><tr><td colspan='2'>Fri Apr 29 02:12:01 2016 UTC</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 2.7.10 64bit [GCC 5.2.1 20151010] \\\\ \\hline\n",
       "IPython & 4.0.2 \\\\ \\hline\n",
       "OS & Linux 4.2.0 30 generic x86\\_64 with Ubuntu 15.10 wily \\\\ \\hline\n",
       "numpy & 1.8.2 \\\\ \\hline\n",
       "scipy & 0.14.1 \\\\ \\hline\n",
       "matplotlib & 1.4.2 \\\\ \\hline\n",
       "sympy & 0.7.6 \\\\ \\hline\n",
       "version_information & 1.0.3 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Apr 29 02:12:01 2016 UTC} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 2.7.10 64bit [GCC 5.2.1 20151010]\n",
       "IPython 4.0.2\n",
       "OS Linux 4.2.0 30 generic x86_64 with Ubuntu 15.10 wily\n",
       "numpy 1.8.2\n",
       "scipy 0.14.1\n",
       "matplotlib 1.4.2\n",
       "sympy 0.7.6\n",
       "version_information 1.0.3\n",
       "Fri Apr 29 02:12:01 2016 UTC"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "\n",
    "%version_information numpy, scipy, matplotlib, sympy, version_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debuging\n",
    "We all write buggy code. Accept it. Deal with it.\n",
    "\n",
    "- Write your code with testing and debugging in mind.\n",
    "- Keep It Simple, Stupid (KISS).\n",
    "    - What is the simplest thing that could possibly work?\n",
    "- Don’t Repeat Yourself (DRY).\n",
    "    - Every piece of knowledge must have a single, unambiguous, authoritative representation within a system. \n",
    "    - Constants, algorithms, etc...\n",
    "- Try to limit interdependencies of your code. (Toward Loose Coupling)\n",
    "- Give your variables, functions and modules meaningful names (not mathematics names)\n",
    "\n",
    "#### pyflakes: fast static analysis\n",
    "Integrating pyflakes (or flake8) in your editor or IDE is highly recommended, it does yield productivity gains.\n",
    "\n",
    "### Debugging workflow\n",
    "If you do have a non trivial bug, this is when debugging strategies kick in. There is no silver bullet. Yet, strategies help:\n",
    "For debugging a given problem, the favorable situation is when the problem is **isolated in a small number of lines of code, outside framework or application code, with short modify-run-fail cycles**\n",
    "\n",
    "1. Make it fail reliably. Find a test case that makes the code fail every time.\n",
    "2. Divide and Conquer. Once you have a failing test case, isolate the failing code.\n",
    "    - Which module.\n",
    "    - Which function.\n",
    "    - Which line of code.\n",
    "    => isolate a small reproducible failure: a test case\n",
    "\n",
    "3. Change one thing at a time and re-run the failing test case.\n",
    "4. Use the debugger to understand what is going wrong.\n",
    "5. Take notes and be patient. It may take a while.\n",
    "\n",
    "### Using the Python debugger\n",
    "\n",
    "#### Postmortem\n",
    "\n",
    "Situation: You’re working in IPython and you get a traceback.\n",
    "Here we debug the file index_error.py. When running it, an IndexError is raised. \n",
    "Type %debug and drop into the debugger.\n",
    "```\n",
    "In [1]: %run index_error.py\n",
    "---------------------------------------------------------------------------\n",
    "IndexError                                Traceback (most recent call last)\n",
    "/home/varoquau/dev/scipy-lecture-notes/advanced/debugging/index_error.py in <module>()\n",
    "      6\n",
    "      7 if __name__ == '__main__':\n",
    "----> 8     index_error()\n",
    "      9\n",
    "\n",
    "/home/varoquau/dev/scipy-lecture-notes/advanced/debugging/index_error.py in index_error()\n",
    "      3 def index_error():\n",
    "      4     lst = list('foobar')\n",
    "----> 5     print lst[len(lst)]\n",
    "      6\n",
    "      7 if __name__ == '__main__':\n",
    "\n",
    "IndexError: list index out of range\n",
    "\n",
    "In [2]: %debug\n",
    "> /home/varoquau/dev/scipy-lecture-notes/advanced/debugging/index_error.py(5)index_error()\n",
    "      4     lst = list('foobar')\n",
    "----> 5     print lst[len(lst)]\n",
    "      6\n",
    "\n",
    "ipdb> list\n",
    "      1 \"\"\"Small snippet to raise an IndexError.\"\"\"\n",
    "      2\n",
    "      3 def index_error():\n",
    "      4     lst = list('foobar')\n",
    "----> 5     print lst[len(lst)]\n",
    "      6\n",
    "      7 if __name__ == '__main__':\n",
    "      8     index_error()\n",
    "      9\n",
    "\n",
    "ipdb> len(lst)\n",
    "6\n",
    "ipdb> print lst[len(lst)-1]\n",
    "r\n",
    "ipdb> quit\n",
    "\n",
    "In [3]:\n",
    "```\n",
    "> In some situations you cannot use IPython, for instance to debug a script that wants to be called from the command line. In this case, you can call the script with python -m pdb script.py:\n",
    "\n",
    "####  Step-by-step execution\n",
    "For instance we are trying to debug wiener_filtering.py. Indeed the code runs, but the filtering does not work well.\n",
    "- Run the script in IPython with the debugger using %run -d wiener_filtering.p :\n",
    "```\n",
    "In [1]: %run -d wiener_filtering.py\n",
    "*** Blank or comment\n",
    "*** Blank or comment\n",
    "*** Blank or comment\n",
    "Breakpoint 1 at /home/varoquau/dev/scipy-lecture-notes/advanced/optimizing/wiener_filtering.py:4\n",
    "NOTE: Enter 'c' at the ipdb>  prompt to start your script.\n",
    "> <string>(1)<module>()\n",
    "```\n",
    "\n",
    "- Set a break point at line 34 using b 34:\n",
    "```\n",
    "ipdb> n\n",
    "> /home/varoquau/dev/scipy-lecture-notes/advanced/optimizing/wiener_filtering.py(4)<module>()\n",
    "      3\n",
    "1---> 4 import numpy as np\n",
    "      5 import scipy as sp\n",
    "\n",
    "ipdb> b 34\n",
    "Breakpoint 2 at /home/varoquau/dev/scipy-lecture-notes/advanced/optimizing/wiener_filtering.py:34\n",
    "```\n",
    "\n",
    "- Continue execution to next breakpoint with c(ont(inue)):\n",
    "```\n",
    "ipdb> c\n",
    "> /home/varoquau/dev/scipy-lecture-notes/advanced/optimizing/wiener_filtering.py(34)iterated_wiener()\n",
    "     33     \"\"\"\n",
    "2--> 34     noisy_img = noisy_img\n",
    "     35     denoised_img = local_mean(noisy_img, size=size)\n",
    "```\n",
    "#### Raising exception on numerical errors\n",
    "\n",
    "When we run the wiener_filtering.py file, the following warnings are raised:\n",
    "```\n",
    "In [2]: %run wiener_filtering.py\n",
    "wiener_filtering.py:40: RuntimeWarning: divide by zero encountered in divide\n",
    "    noise_level = (1 - noise/l_var )\n",
    "```\n",
    "\n",
    "We can turn these warnings in exception, which enables us to do post-mortem debugging on them, and find our problem more quickly:\n",
    "\n",
    "```\n",
    "In [3]: np.seterr(all='raise')\n",
    "Out[3]: {'divide': 'print', 'invalid': 'print', 'over': 'print', 'under': 'ignore'}\n",
    "In [4]: %run wiener_filtering.py\n",
    "---------------------------------------------------------------------------\n",
    "FloatingPointError                        Traceback (most recent call last)\n",
    "/home/esc/anaconda/lib/python2.7/site-packages/IPython/utils/py3compat.pyc in execfile(fname, *where)\n",
    "    176             else:\n",
    "    177                 filename = fname\n",
    "--> 178             __builtin__.execfile(filename, *where)\n",
    "\n",
    "/home/esc/physique-cuso-python-2013/scipy-lecture-notes/advanced/debugging/wiener_filtering.py in <module>()\n",
    "     55 pl.matshow(noisy_face[cut], cmap=pl.cm.gray)\n",
    "     56\n",
    "---> 57 denoised_face = iterated_wiener(noisy_face)\n",
    "     58 pl.matshow(denoised_face[cut], cmap=pl.cm.gray)\n",
    "     59\n",
    "\n",
    "/home/esc/physique-cuso-python-2013/scipy-lecture-notes/advanced/debugging/wiener_filtering.py in iterated_wiener(noisy_img, size)\n",
    "     38         res = noisy_img - denoised_img\n",
    "     39         noise = (res**2).sum()/res.size\n",
    "---> 40         noise_level = (1 - noise/l_var )\n",
    "     41         noise_level[noise_level<0] = 0\n",
    "     42         denoised_img += noise_level*res\n",
    "\n",
    "FloatingPointError: divide by zero encountered in divide\n",
    "```\n",
    "\n",
    "#### Graphical debuggers and alternatives\n",
    "- For stepping through code and inspecting variables, you might find it more convenient to use a graphical debugger such as winpdb.\n",
    "- Alternatively, pudb is a good semi-graphical debugger with a text user interface in the console.\n",
    "- Also, the pydbgr project is probably worth looking at.\n",
    "\n",
    "### Debugging segmentation faults using gdb\n",
    "If you have a segmentation fault, **you cannot debug it with pdb, as it crashes the Python interpreter before it can drop in the debugger.** Similarly, if you have a bug in C code embedded in Python, pdb is useless. For this we turn to the gnu debugger, gdb, available on Linux.\n",
    "\n",
    "Before we start with gdb, let us add a few Python-specific tools to it. For this we add a few macros to our ~/.gbdinit. The optimal choice of macro depends on your Python version and your gdb version. I have added a simplified version in gdbinit, but feel free to read https://wiki.python.org/moin/DebuggingWithGdb\n",
    "\n",
    "To debug with gdb the Python script segfault.py, we can run the script in gdb as follows\n",
    "```\n",
    "gdb python\n",
    "...\n",
    "(gdb) run segfault.py\n",
    "Starting program: /usr/bin/python segfault.py\n",
    "[Thread debugging using libthread_db enabled]\n",
    "\n",
    "Program received signal SIGSEGV, Segmentation fault.\n",
    "_strided_byte_copy (dst=0x8537478 \"\\360\\343G\", outstrides=4, src=\n",
    "    0x86c0690 <Address 0x86c0690 out of bounds>, instrides=32, N=3,\n",
    "    elsize=4)\n",
    "        at numpy/core/src/multiarray/ctors.c:365\n",
    "365            _FAST_MOVE(Int32);\n",
    "(gdb)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize\n",
    "1. Make it work: write the code in a simple legible ways.\n",
    "2. Make it work reliably: write automated test cases, make really sure that your algorithm is right and that if you break it, the tests will capture the breakage.\n",
    "3. Optimize the code by profiling simple use-cases to find the bottlenecks and speeding up these bottleneck, finding a better algorithm or implementation. Keep in mind that a trade off should be found between profiling on a realistic example and the simplicity and speed of execution of the code. \n",
    "\n",
    "#### Timeit\n",
    "In IPython, use timeit (https://docs.python.org/library/timeit.html) to time elementary operations\n",
    "> For long running calls, using %time instead of %timeit; it is less precise but faster\n",
    "\n",
    "####  Profiler\n",
    "\n",
    "Useful when you have a large program to profile, for example the following file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Profiling outside of IPython, running ``cProfile``\n",
    "\n",
    "Similar profiling can be done outside of IPython, simply calling the built-in Python profilers cProfile and profile.\n",
    "```\n",
    "$  python -m cProfile -o demo.prof demo.py\n",
    "```\n",
    "\n",
    "Using the -o switch will output the profiler results to the file demo.prof to view with an external tool. This can be useful if you wish to process the profiler output with a visualization tool.\n",
    "\n",
    "\n",
    "#### Line-profiler\n",
    "\n",
    "The profiler tells us which function takes most of the time, **but not where it is called**.\n",
    "For this, we use the line_profiler: in the source file, we decorate a few functions that we want to inspect with @profile (no need to import it)\n",
    "```\n",
    "@profile\n",
    "def test():\n",
    "    data = np.random.random((5000, 100))\n",
    "    u, s, v = linalg.svd(data)\n",
    "    pca = np.dot(u[:, :10], data)\n",
    "    results = fastica(pca.T, whiten=False)\n",
    "```\n",
    "Then we run the script using the kernprof.py program, with switches -l, --line-by-line and -v, --view to use the line-by-line profiler and view the results in addition to saving them:\n",
    "```\n",
    "$ kernprof.py -l -v demo.py\n",
    "\n",
    "Wrote profile results to demo.py.lprof\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "File: demo.py\n",
    "Function: test at line 5\n",
    "Total time: 14.2793 s\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "=========== ============ ===== ========= ======= ==== ========\n",
    "    5                                           @profile\n",
    "    6                                           def test():\n",
    "    7         1        19015  19015.0      0.1      data = np.random.random((5000, 100))\n",
    "    8         1     14242163 14242163.0   99.7      u, s, v = linalg.svd(data)\n",
    "    9         1        10282  10282.0      0.1      pca = np.dot(u[:10, :], data)\n",
    "   10         1         7799   7799.0      0.1      results = fastica(pca.T, whiten=False)\n",
    "```\n",
    "The SVD is taking all the time. We need to optimise this line.\n",
    "\n",
    "> Computational linear algebra\n",
    "For certain algorithms, many of the bottlenecks will be linear algebra computations. In this case, using the right function to solve the right problem is key. For instance, an eigenvalue problem with a symmetric matrix is easier to solve than with a general matrix. Also, most often, you can avoid inverting a matrix and use a less costly (and more numerically stable) operation.\n",
    "\n",
    "Know your computational linear algebra. When in doubt, explore scipy.linalg, and use %timeit to try out different alternatives on your data.\n",
    "\n",
    "#### Writing faster numerical code\n",
    "A complete discussion on advanced use of numpy is found in chapter Advanced Numpy, or in the article The NumPy array: a structure for efficient numerical computation by van der Walt et al. Here we discuss only some commonly encountered tricks to make code faster.\n",
    "\n",
    "- Vectorizing for loops\n",
    "    - Find tricks to avoid for loops using numpy arrays. For this, masks and indices arrays can be useful.\n",
    "- Broadcasting\n",
    "    - Use broadcasting to do operations on arrays as small as possible before combining them.\n",
    "- In place operations\n",
    "\n",
    "```\n",
    "In [1]: a = np.zeros(1e7)\n",
    "\n",
    "In [2]: %timeit global a ; a = 0*a\n",
    "10 loops, best of 3: 111 ms per loop\n",
    "\n",
    "In [3]: %timeit global a ; a *= 0\n",
    "10 loops, best of 3: 48.4 ms per loop\n",
    "```\n",
    "\n",
    "> we need global a in the timeit so that it work, as it is assigning to a, and thus considers it as a local variabl\n",
    "\n",
    "- Be easy on the memory: use views, and not copies\n",
    "    - Copying big arrays is as costly as making simple numerical operations on them:\n",
    "\n",
    "```\n",
    "In [1]: a = np.zeros(1e7)\n",
    "\n",
    "In [2]: %timeit a.copy()\n",
    "10 loops, best of 3: 124 ms per loop\n",
    "\n",
    "In [3]: %timeit a + 1\n",
    "10 loops, best of 3: 112 ms per loop\n",
    "```\n",
    "\n",
    "- Beware of cache effects\n",
    "Memory access is cheaper when it is grouped: accessing a big array in a continuous way is much faster than random access. This implies amongst other things that smaller strides are faster (see CPU cache effects):\n",
    "\n",
    "```\n",
    "In [1]: c = np.zeros((1e4, 1e4), order='C')\n",
    "\n",
    "In [2]: %timeit c.sum(axis=0)\n",
    "1 loops, best of 3: 3.89 s per loop\n",
    "\n",
    "In [3]: %timeit c.sum(axis=1)\n",
    "1 loops, best of 3: 188 ms per loop\n",
    "\n",
    "In [4]: c.strides\n",
    "Out[4]: (80000, 8)\n",
    "```\n",
    "\n",
    "This is the reason why Fortran ordering or C ordering may make a big difference on operations:\n",
    "\n",
    "```\n",
    "In [5]: a = np.random.rand(20, 2**18)\n",
    "\n",
    "In [6]: b = np.random.rand(20, 2**18)\n",
    "\n",
    "In [7]: %timeit np.dot(b, a.T)\n",
    "1 loops, best of 3: 194 ms per loop\n",
    "\n",
    "In [8]: c = np.ascontiguousarray(a.T)\n",
    "\n",
    "In [9]: %timeit np.dot(b, c)\n",
    "10 loops, best of 3: 84.2 ms per loop\n",
    "```\n",
    "\n",
    "Note that copying the data to work around this effect may not be worth it:\n",
    "\n",
    "```\n",
    "In [10]: %timeit c = np.ascontiguousarray(a.T)\n",
    "10 loops, best of 3: 106 ms per loop\n",
    "```\n",
    "\n",
    "Using numexpr can be useful to automatically optimize code for such effects.\n",
    "\n",
    "- Use compiled code\n",
    "The last resort, once you are sure that all the high-level optimizations have been explored, is to transfer the hot spots, i.e. the few lines or functions in which most of the time is spent, to compiled code. For compiled code, the preferred option is to use Cython: it is easy to transform exiting Python code in compiled code, and with a good use of the numpy support yields efficient code on numpy arrays, for instance by unrolling loops.\n",
    "\n",
    "For more info refers to http://www.scipy-lectures.org/advanced/optimizing/index.html#additional-links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interfacing with C\n",
    "http://www.scipy-lectures.org/advanced/interfacing_with_c/interfacing_with_c.html\n",
    "\n",
    "http://nbviewer.jupyter.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-6A-Fortran-and-C.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (Ubuntu, plain)",
   "language": "python",
   "name": "python2-ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "00_Scientific-Computing-with-Python.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
