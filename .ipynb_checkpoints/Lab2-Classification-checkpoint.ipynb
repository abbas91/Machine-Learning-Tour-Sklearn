{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "## Let's start!!\n",
    "![](https://i.imgur.com/ArhCF7i.png)\n",
    "\n",
    "如課堂所說，監督式學習運用data萃取出矩陣``X``(shape 為``[n_samples, n_features]`` )和給定的``label`` 來 train model。在``scikit-learn``中target的shape為``(n_samples,)``。\n",
    "\n",
    "訓練之後我們可以輸入新的``X_new``來得出新的``y_new``\n",
    " \n",
    "    \n",
    "## Classification\n",
    "這個範例用來展示scikit-learn 機器學習套件，如何用SVM Classifier(目前當成黑盒子即可)來達成手寫的數字辨識\n",
    "\n",
    "- 利用 make_classification 建立模擬資料\n",
    "- 利用 sklearn.datasets.load_digits() 來讀取內建資料庫\n",
    "- 用線性的SVC來做分類，以8x8的影像之像素值來當作特徵(共64個特徵)\n",
    "- 用 metrics.classification_report 來提供辨識報表\n",
    "\n",
    "> 在 scikit-learn中一個 estimator物件 (不論是supervise 或 unsupervised )都會實做 ``fit(X, y)`` 和 ``predict(X_new)``這兩個function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來的步驟則是用``classifier = svm.SVC(gamma=0.001)``產生一個SVC分類器(Support Vector Classification)。\n",
    "\n",
    "再將一半的資料送入分類器來訓練``classifier.fit``(資料:898x64, 分類目標:898x1)\n",
    "\n",
    "最後再利用後半部份的資料來測試訓練完成的``SVC``分類器``predict(data[n_samples/2:])``將預測結果存入``predicted``變數。\n",
    "\n",
    "原先的真實目標資料則存於``expected``變數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, n_features = digits.data.shape\n",
    "# 產生SVC分類器\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "\n",
    "# 用前半部份的資料來訓練\n",
    "clf.fit(digits.data[:n_samples/2], digits.target[:n_samples/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected = digits.target[n_samples/2:]\n",
    "\n",
    "#利用後半部份的資料來測試分類器，共 899筆資料\n",
    "predicted = clf.predict(digits.data[n_samples/2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若是觀察 expected 及 predicted 矩陣中之前10個變數可以得到:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8, 8, 4, 9, 0, 8, 9, 8, 1, 2]), array([8, 8, 4, 9, 0, 8, 9, 8, 1, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected[:10], predicted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這說明了前10個元素中，我們之前訓練完成的分類機，正確的分類了手寫數字資料!! 那對於全部測試資料的準確度呢？要如何確認呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96885428253615125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "判斷準確度方面，我們可以使用一個名為 ``Confusion matrix`` 的方式來統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\"% metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "圖像化表示此矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ds/lib/python2.7/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fbdd7e21b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(np.log(metrics.confusion_matrix(expected, predicted)), cmap='Blues', interpolation='nearest')\n",
    "plt.grid(False)\n",
    "plt.ylabel('true')\n",
    "plt.xlabel('predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用``sklearn``中之``metrics``物件，``metrics.confusion_matrix``(真實資料:899, 預測資料:899)可以列出上面矩陣。此矩陣對角線左上方第一個數字 87，代表實際為``0``且預測為``0``的總數有87個，同一列(row)第五個元素則代表，實際為``0``但判斷為``4``的資料個數為1個。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以手寫影像3為例，我們可以用四個數字來探討判斷的精準度。\n",
    "\n",
    "- True Positive(TP):實際為3且判斷為3，共79個\n",
    "- False Positive(FP):判斷為3但判斷錯誤，共2個\n",
    "- False Negative(FN):實際為3但判斷錯誤，共12個\n",
    "- True Negative(TN):實際不為3，且判斷正確。也就是其餘899-79-2-12=885個\n",
    "\n",
    "以手寫影像3為例準確度為\n",
    "\n",
    "- precision = TP/(TP+FP) = 79/81 = 0.98 #判斷為3且實際為3的比例為0.98\n",
    "\n",
    "更多的相關數據可自動產生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\" % (clf, metrics.classification_report(expected, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們將部分的影像和預測結果一起標示出來，錯誤的地方將用宏色來標示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.data[n_samples/2:][i].reshape(8, 8), cmap='binary')\n",
    "    ax.text(0.05, 0.05, str(predicted[i]),\n",
    "            transform=ax.transAxes,\n",
    "            color='green' if (expected[i] == predicted[i]) else 'red')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們一般會將``model(weights)``存下來方便下次做prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "clf = svm.SVC()\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf.fit(X, y)\n",
    "\n",
    "import pickle\n",
    "s = pickle.dumps(clf)\n",
    "clf2 = pickle.loads(s)\n",
    "clf2.predict(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Yet Another Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K nearest neighbors (kNN) 是最簡潔的機器學習演算法之一，在訓練階段他只是把輸入的data相關參數和給的label存起來，之後給定一個新的data，他會去找空間上最近的``k``個點，然後讓這``k``個點做投票屬於哪類，最多的那類就是預測結果! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# create the model\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model\n",
    "knn.fit(X, y)\n",
    "\n",
    "# What kind of iris has 3cm x 5cm sepal and 4cm x 2cm petal?\n",
    "# call the \"predict\" method:\n",
    "result = knn.predict([[3, 5, 4, 2],])\n",
    "\n",
    "print(iris.target_names[result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.8,  0.2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba([[3, 5, 4, 2],]) #也可以用來算出機率!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fig_code import plot_iris_knn\n",
    "plot_iris_knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
